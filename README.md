# ğŸ—ï¸ K8s-LLM-Inference-Platform

> Kubernetes äº‘åŸç”Ÿ AI æ¨ç†æœåŠ¡è¿ç»´å¹³å°

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-K3s-orange)](https://kubernetes.io/)
[![vLLM](https://img.shields.io/badge/AI-vLLM-purple)](https://vllm.ai/)

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„ **Kubernetes äº‘åŸç”Ÿ AI æ¨ç†æœåŠ¡è¿ç»´å¹³å°** è§£å†³æ–¹æ¡ˆï¼ŒåŸºäº K3s + vLLM + Prometheus + Grafana æŠ€æœ¯æ ˆï¼Œå®ç°äº†å¤§è¯­è¨€æ¨¡å‹æ¨ç†æœåŠ¡çš„ä¸€é”®éƒ¨ç½²ã€ç›‘æ§å‘Šè­¦å’Œå¼¹æ€§ä¼¸ç¼©ã€‚

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç”¨æˆ·è®¿é—®å±‚                                  â”‚
â”‚                    (Traefik / Nginx Ingress)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        K8s é›†ç¾¤å±‚ (K3s)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    LLM Serving                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚  â”‚ vLLM Pod    â”‚  â”‚ vLLM Pod    â”‚  â”‚ vLLM Pod    â”‚        â”‚   â”‚
â”‚  â”‚  â”‚ (Qwen2.5-7B)â”‚  â”‚ (Qwen2.5-7B)â”‚  â”‚ (Qwen2.5-7B)â”‚        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç›‘æ§å±‚       â”‚          â”‚  å­˜å‚¨å±‚          â”‚        â”‚  ç½‘ç»œå±‚     â”‚
â”‚               â”‚          â”‚                  â”‚        â”‚             â”‚
â”‚ â€¢ Prometheus  â”‚          â”‚ â€¢ æœ¬åœ°å­˜å‚¨       â”‚        â”‚ â€¢ Traefik   â”‚
â”‚ â€¢ Grafana    â”‚          â”‚ â€¢ PVC           â”‚        â”‚ â€¢ Service   â”‚
â”‚ â€¢ DCGM Exp   â”‚          â”‚ â€¢ ConfigMap     â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â€¢ Ingress  â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | æè¿° |
|------|------|
| **ä¸€é”®éƒ¨ç½²** | Helm Chart ä¸€é”®éƒ¨ç½² vLLM æ¨ç†æœåŠ¡ |
| **GPU è°ƒåº¦** | NVIDIA Device Plugin æ”¯æŒ GPU è°ƒåº¦ |
| **å¼¹æ€§ä¼¸ç¼©** | HPA è‡ªåŠ¨æ ¹æ®è´Ÿè½½æ‰©ç¼©å®¹ |
| **å…¨é“¾è·¯ç›‘æ§** | Prometheus + Grafana + DCGM Exporter |
| **æ™ºèƒ½å‘Šè­¦** | ä¸‰çº§å‘Šè­¦ (è½»å¾®/ä¸¥é‡/ç´§æ€¥) |
| **é«˜å¯ç”¨** | å¤šå‰¯æœ¬éƒ¨ç½² + å¥åº·æ£€æŸ¥ |

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **å®¹å™¨ç¼–æ’**: Kubernetes (K3s / é˜¿é‡Œäº‘ ACK)
- **AI æ¨ç†æ¡†æ¶**: vLLM (PagedAttention)
- **æ¨¡å‹**: Qwen2.5-7B-Instruct
- **ç›‘æ§**: Prometheus + Grafana + node_exporter + DCGM Exporter
- **å­˜å‚¨**: Local Path Provisioner
- **Ingress**: Traefik / Nginx Ingress
- **éƒ¨ç½²å·¥å…·**: Helm + Ansible

## ğŸ“ é¡¹ç›®ç»“æ„

```
k8s-llm-inference-platform/
â”œâ”€â”€ k8s/                    # Kubernetes YAML é…ç½®
â”‚   â”œâ”€â”€ namespace.yaml       # å‘½åç©ºé—´
â”‚   â”œâ”€â”€ configmap.yaml       # é…ç½®
â”‚   â”œâ”€â”€ pvc.yaml           # æŒä¹…åŒ–å­˜å‚¨
â”‚   â”œâ”€â”€ deployment.yaml    # éƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ service.yaml       # æœåŠ¡
â”‚   â”œâ”€â”€ ingress.yaml       # å…¥å£
â”‚   â”œâ”€â”€ hpa.yaml          # è‡ªåŠ¨ä¼¸ç¼©
â”‚   â””â”€â”€ servicemonitor.yaml # ç›‘æ§æœåŠ¡
â”‚
â”œâ”€â”€ helm/                   # Helm Chart
â”‚   â””â”€â”€ llm-inference/     # vLLM æ¨ç†æœåŠ¡ Chart
â”‚
â”œâ”€â”€ docker/                  # Docker é•œåƒ
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ansible/                # Ansible è‡ªåŠ¨åŒ–
â”‚   â””â”€â”€ playbooks/
â”‚
â”œâ”€â”€ scripts/                # è¿ç»´è„šæœ¬
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”œâ”€â”€ benchmark.sh
â”‚   â””â”€â”€ monitor.sh
â”‚
â”œâ”€â”€ docs/                   # æ–‡æ¡£
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ demo/                   # æ¼”ç¤ºæ–‡ä»¶
    â””â”€â”€ ...
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | æœ€ä½é…ç½® |
|------|----------|
| Kubernetes | K3s / ACK |
| GPU | NVIDIA T4 / A10 (16GB+ æ˜¾å­˜) |
| å†…å­˜ | 32GB+ |
| ç³»ç»Ÿ | Ubuntu 22.04 |

### 2. éƒ¨ç½²æ­¥éª¤

```bash
# 1. å®‰è£… K3s
curl -sfL https://get.k3s.io | sh -

# 2. å®‰è£… NVIDIA Device Plugin
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.5/nvidia-device-plugin.yml

# 3. éƒ¨ç½² vLLM æ¨ç†æœåŠ¡
kubectl apply -f k8s/

# 4. æˆ–ä½¿ç”¨ Helm éƒ¨ç½²
helm install llm-serving helm/llm-inference/

# 5. éƒ¨ç½²ç›‘æ§
helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring
```

### 3. éªŒè¯éƒ¨ç½²

```bash
# æŸ¥çœ‹ Pod çŠ¶æ€
kubectl get pods -n llm-serving

# æµ‹è¯• API
curl http://<your-ip>:8000/v1/models

# æŸ¥çœ‹ç›‘æ§é¢æ¿
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

é…å¥—å‹æµ‹ç»“æœæ–‡æ¡£ï¼š[BENCHMARK_RESULTS.md](./BENCHMARK_RESULTS.md)

![å‹æµ‹ç»“æœ](æ™ºç®—ç›‘æ§ä¸­å¿ƒ.png)

### æµ‹è¯•äº®ç‚¹

- **ååé‡**: 26-30 tokens/s ç¨³å®šè¾“å‡º
- **å¹¶å‘èƒ½åŠ›**: æœ€é«˜æ”¯æŒ 20 å¹¶å‘ï¼ŒQPS è¾¾ 2.34
- **æˆåŠŸç‡**: 100% é›¶å¤±è´¥
- **é¦– Token å»¶è¿Ÿ**: ä½è‡³ 42ms

### å‹æµ‹é…ç½®

| é…ç½® | å€¼ |
|------|-----|
| æ¨¡å‹ | Qwen2.5-7B-Instruct |
| GPU | NVIDIA A10 (24GB) |
| æ¨ç†æ¡†æ¶ | vLLM |

## ğŸ”” å‘Šè­¦è§„åˆ™

| çº§åˆ« | é˜ˆå€¼ | ç¤ºä¾‹ |
|------|------|------|
| ğŸŸ¡ è½»å¾® | > 70% | CPU/å†…å­˜ä½¿ç”¨ç‡åé«˜ |
| ğŸŸ  ä¸¥é‡ | > 85% | GPU æ˜¾å­˜ç´§å¼ ã€Pod Pending |
| ğŸ”´ ç´§æ€¥ | > 95% | èµ„æºè€—å°½ã€Pod Failed |

## ğŸ“š æ–‡æ¡£

- [å®æ–½æŒ‡å¯¼ä¹¦](./é¡¹ç›®1ï¼šKubernetes_äº‘åŸç”Ÿ_AI_æ¨ç†æœåŠ¡è¿ç»´å¹³å°_Â·_å®æ–½æŒ‡å¯¼ä¹¦_305afb83e0458014a612ecb96dd6dc02.md)
- [K8s éƒ¨ç½²é…ç½®](./k8s/)
- [Helm Chart](./helm/)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

---

*å¦‚æœå¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ Star â­*
